# A Comprehensive Survey of CLIP Powered Domain Generalization and Adaptation: Review and Beyond

## Domain Generalization

### Prompt Learning Optimization
1. [Learning to prompt for vision-language models](https://arxiv.org/abs/2109.01134)
2. [Conditional prompt learning for vision-language models](https://arxiv.org/abs/2203.05557)
3. [Maple: Multi-modal prompt learning](https://arxiv.org/abs/2210.03117)
4. [LAMM: Label Alignment for Multi-Modal Prompt Learning](https://arxiv.org/abs/2312.08212)

### Adopted as Backbone or Encoder
#### Source-Available (SA)

#### Source-Free (SF)


## Domain Adaptation

### Source-Available
#### Single-Source
##### Source-Available Domain Adaptation (SA-DA)
##### Source-Available Close-Set Unsupervised Domain Adaptation (SA-UDA)
##### Source-Available Open-Set Unsupervised Domain Adaptation (SA-OSUDA)
#### Multi-Source
##### Multi-Source Unsupervised Domain Adaptation (MS-UDA)
1. [Multi-Prompt Alignment for Multi-Source Unsupervised Domain Adaptation](https://arxiv.org/abs/2209.15210)
2. [LanDA: Language-Guided Multi-Source Domain Adaptation](https://arxiv.org/abs/2401.14148)
3. [Semantic-Aware Adaptive Prompt Learning for Universal Multi-Source Domain Adaptation](https://ieeexplore.ieee.org/document/10502133)
##### Multi-Source Few-Shot Domain Adaptation (MS-FSDA)
1. [Domain Prompt Matters a Lot in Multi-Source Few-Shot Domain Adaptation](https://openreview.net/forum?id=YRJDZYGmAZ)


### Source-Free

#### Source-Free Domain Adaptation (SF-DA)

#### Source-Free Unsupervised Domain Adaptation (SF-UDA)

## Challenges and Opportunities

## Future Directions
